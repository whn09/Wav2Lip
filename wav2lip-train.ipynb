{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a35e39",
   "metadata": {
    "papermill": {
     "duration": 0.03953,
     "end_time": "2021-08-02T15:03:04.941630",
     "exception": false,
     "start_time": "2021-08-02T15:03:04.902100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Wav2Lip\n",
    "**[Wav2Lip](https://arxiv.org/pdf/2008.10010.pdf)** 是一种基于对抗生成网络的由语音驱动的人脸说话视频生成模型。如下图所示，Wav2Lip的网络模型总体上分成三块：生成器、判别器和一个预训练好的Lip-Sync Expert组成。网络的输入有2个：任意的一段视频和一段语音，输出为一段唇音同步的视频。生成器是基于encoder-decoder的网络结构，分别利用2个encoder: speech encoder, identity encoder去对输入的语音和视频人脸进行编码，并将二者的编码结果进行拼接，送入到 face decoder 中进行解码得到输出的视频帧。判别器Visual Quality Discriminator对生成结果的质量进行规范，提高生成视频的清晰度。为了更好的保证生成结果的唇音同步性，Wav2Lip引入了一个预预训练的唇音同步判别模型 Pre-trained Lip-sync Expert，作为衡量生成结果的唇音同步性的额外损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34513e2",
   "metadata": {
    "papermill": {
     "duration": 0.037914,
     "end_time": "2021-08-02T15:03:05.018513",
     "exception": false,
     "start_time": "2021-08-02T15:03:04.980599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Lip-Sync Expert\n",
    "Lip-sync Expert基于 **[SyncNet](https://www.robots.ox.ac.uk/~vgg/publications/2016/Chung16a/)**，是一种用来判别语音和视频是否同步的网络模型。如下图所示，SyncNet的输入也是两种：语音特征MFCC和嘴唇的视频帧，利用两个基于卷积神经网络的Encoder分别对输入的语音和视频帧进行降纬和特征提取，将二者的特征都映射到同一个纬度空间中去，最后利用contrastive loss对唇音同步性进行衡量，结果的值越大代表越不同步，结果值越小则代表越同步。在Wav2Lip模型中，进一步改进了SyncNet的网络结构：网络更深；加入了残差网络结构；输入的语音特征被替换成了mel-spectrogram特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461cfed",
   "metadata": {
    "papermill": {
     "duration": 0.07419,
     "end_time": "2021-08-02T15:03:05.158517",
     "exception": false,
     "start_time": "2021-08-02T15:03:05.084327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. 环境的配置\n",
    "- `建议准备一台有显卡的linux系统电脑，或者可以选择使用第三方云服务器（Google Colab）` \n",
    "- `Python 3.6 或者更高版本` \n",
    "- ffmpeg: `sudo apt-get install ffmpeg`\n",
    "- 必要的python包的安装，所需要的库名称都已经包含在`requirements.txt`文件中，可以使用 `pip install -r requirements.txt`一次性安装. \n",
    "- 在本实验中利用到了人脸检测的相关技术，需要下载人脸检测预训练模型：Face detection [pre-trained model](https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth) 并移动到 `face_detection/detection/sfd/s3fd.pth`文件夹下. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1514d8",
   "metadata": {
    "papermill": {
     "duration": 0.081877,
     "end_time": "2021-08-02T15:03:05.314858",
     "exception": false,
     "start_time": "2021-08-02T15:03:05.232981",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting librosa>=0.7.0 (from -r requirements.txt (line 1))\n",
      "  Using cached librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
      "Requirement already satisfied: numpy>=1.17.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.24.3)\n",
      "Collecting opencv-contrib-python>=4.2.0.34 (from -r requirements.txt (line 3))\n",
      "  Using cached opencv_contrib_python-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.8 MB)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.6.0.66)\n",
      "Requirement already satisfied: torch>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: torchvision>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.15.1)\n",
      "Requirement already satisfied: tqdm>=4.45.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (4.65.0)\n",
      "Requirement already satisfied: numba>=0.48 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.57.0)\n",
      "Collecting audioread>=2.1.9 (from librosa>=0.7.0->-r requirements.txt (line 1))\n",
      "  Using cached audioread-3.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa>=0.7.0->-r requirements.txt (line 1)) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa>=0.7.0->-r requirements.txt (line 1)) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa>=0.7.0->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa>=0.7.0->-r requirements.txt (line 1)) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa>=0.7.0->-r requirements.txt (line 1))\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_17_x86_64.whl (1.3 MB)\n",
      "Collecting pooch<1.7,>=1.0 (from librosa>=0.7.0->-r requirements.txt (line 1))\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting soxr>=0.3.2 (from librosa>=0.7.0->-r requirements.txt (line 1))\n",
      "  Downloading soxr-0.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa>=0.7.0->-r requirements.txt (line 1)) (4.5.0)\n",
      "Collecting lazy-loader>=0.1 (from librosa>=0.7.0->-r requirements.txt (line 1))\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Collecting msgpack>=1.0 (from librosa>=0.7.0->-r requirements.txt (line 1))\n",
      "  Downloading msgpack-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.8/316.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.1.0->-r requirements.txt (line 5)) (3.12.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.1.0->-r requirements.txt (line 5)) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.1.0->-r requirements.txt (line 5)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.1.0->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision>=0.3.0->-r requirements.txt (line 6)) (2.29.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision>=0.3.0->-r requirements.txt (line 6)) (9.5.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from numba>=0.48->-r requirements.txt (line 8)) (0.40.0)\n",
      "Collecting appdirs>=1.3.0 (from pooch<1.7,>=1.0->librosa>=0.7.0->-r requirements.txt (line 1))\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pooch<1.7,>=1.0->librosa>=0.7.0->-r requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchvision>=0.3.0->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchvision>=0.3.0->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchvision>=0.3.0->-r requirements.txt (line 6)) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->torchvision>=0.3.0->-r requirements.txt (line 6)) (2023.5.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa>=0.7.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa>=0.7.0->-r requirements.txt (line 1)) (1.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.1.0->-r requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.1.0->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.7.0->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->pooch<1.7,>=1.0->librosa>=0.7.0->-r requirements.txt (line 1)) (3.0.9)\n",
      "Installing collected packages: msgpack, appdirs, soxr, opencv-contrib-python, lazy-loader, audioread, soundfile, pooch, librosa\n",
      "  Attempting uninstall: pooch\n",
      "    Found existing installation: pooch 1.7.0\n",
      "    Uninstalling pooch-1.7.0:\n",
      "      Successfully uninstalled pooch-1.7.0\n",
      "Successfully installed appdirs-1.4.4 audioread-3.0.0 lazy-loader-0.3 librosa-0.10.0.post2 msgpack-1.0.5 opencv-contrib-python-4.8.0.74 pooch-1.6.0 soundfile-0.12.1 soxr-0.3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c15ff",
   "metadata": {
    "papermill": {
     "duration": 0.065854,
     "end_time": "2021-08-02T15:03:05.446911",
     "exception": false,
     "start_time": "2021-08-02T15:03:05.381057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. 数据集的准备及预处理\n",
    "\n",
    "**LRS2 数据集的下载**  \n",
    "实验所需要的数据集下载地址为：<a href=\"http://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs2.html\">LRS2 dataset</a>，下载该数据集需要获得BBC的许可，需要发送申请邮件以获取下载密钥，具体操作详见网页中的指示。下载完成后对数据集进行解压到本目录的`mvlrs_v1/`文件夹下，并将LRS2中的文件列表文件`train.txt, val.txt, test.txt` 移动到`filelists/`文件夹下，最终得到的数据集目录结构如下所示。\n",
    "```\n",
    "data_root (mvlrs_v1)\n",
    "├── main, pretrain (我们只使用main文件夹下的数据)\n",
    "|\t├── 文件夹列表\n",
    "|\t│   ├── 5位以.mp4结尾的视频ID\n",
    "```\n",
    "**数据集预处理**\n",
    "数据集中大多数视频都是包含人的半身或者全身的画面，而我们的模型只需要人脸这一小部分。所以在预处理阶段，我们要对每一个视频进行分帧操作，提取视频的每一帧，之后使用`face detection`工具包对人脸位置进行定位并裁减，只保留人脸的图片帧。同时，我们也需要将每一个视频中的语音分离出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931aaa3d-6eab-44f9-9cc0-d6e17fe80c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O face_detection/detection/sfd/s3fd.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bccdb9-1b21-48d4-a983-6f2add90b315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf ../LSR2/demo\n",
    "!mkdir -p ../LSR2/demo\n",
    "!cp -r ../LSR2/main/553* ../LSR2/demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b53dcfde",
   "metadata": {
    "papermill": {
     "duration": 0.076313,
     "end_time": "2021-08-02T15:03:05.590493",
     "exception": false,
     "start_time": "2021-08-02T15:03:05.514180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started processing for ../LSR2/demo with 1 GPUs\n",
      "100%|█████████████████████████████████████████| 432/432 [07:59<00:00,  1.11s/it]\n",
      "Dumping audios...\n",
      "100%|█████████████████████████████████████████| 432/432 [00:08<00:00, 49.30it/s]\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ../LSR2/lrs2_preprocessed\n",
    "!python preprocess.py --data_root \"../LSR2/main\" --preprocessed_root \"../LSR2/lrs2_preprocessed\" --batch_size 128\n",
    "# !python preprocess.py --data_root \"../LSR2/demo\" --preprocessed_root \"../LSR2/lrs2_preprocessed\" --batch_size 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e70f29",
   "metadata": {
    "papermill": {
     "duration": 0.057029,
     "end_time": "2021-08-02T15:03:05.717822",
     "exception": false,
     "start_time": "2021-08-02T15:03:05.660793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "预处理后的`lrs2_preprocessed/`文件夹下的目录结构如下\n",
    "```\n",
    "preprocessed_root (lrs2_preprocessed)\n",
    "├── 文件夹列表\n",
    "|\t├── 五位的视频ID\n",
    "|\t│   ├── *.jpg\n",
    "|\t│   ├── audio.wav\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff5bb63-382e-4670-bd8e-aa6d7702c34d",
   "metadata": {},
   "source": [
    "获取对应的文件列表并更新到filelists/train.txt和filelists/eval.txt。只保存对应的视频名称即可。代码可以参考，对视频样本重命名并生成对应的命名列表，此处视频文件数量过少<2，会报错："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c52dd89-d180-4fac-900b-219cd4147b98",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5535864093654496929', '5538635636050605931', '5537751731781090844', '5537369050195015499', '5537514649586349811', '5539474443163516678', '5537522380527482610', '5536266102593401990', '5536915501648559593', '5539826200985059108', '5539535002202392187', '5539702505926936192', '5535423430009926848', '5537693749722594824', '5536968329746298779', '5539741160632598296', '5537885734760724252', '5535496873950688380', '5535415699068794046', '5537893465701857051', '5536760882825901738', '5536745420943636139', '5537143564411975377', '5539444807889172133', '5536038039829982468', '5536876846942893978']\n",
      "dirpath: 5535864093654496929\n",
      "dirpath: 5538635636050605931\n",
      "dirpath: 5537751731781090844\n",
      "dirpath: 5537369050195015499\n",
      "dirpath: 5537514649586349811\n",
      "dirpath: 5539474443163516678\n",
      "dirpath: 5537522380527482610\n",
      "dirpath: 5536266102593401990\n",
      "dirpath: 5536915501648559593\n",
      "dirpath: 5539826200985059108\n",
      "dirpath: 5539535002202392187\n",
      "dirpath: 5539702505926936192\n",
      "dirpath: 5535423430009926848\n",
      "dirpath: 5537693749722594824\n",
      "dirpath: 5536968329746298779\n",
      "dirpath: 5539741160632598296\n",
      "dirpath: 5537885734760724252\n",
      "dirpath: 5535496873950688380\n",
      "dirpath: 5535415699068794046\n",
      "dirpath: 5537893465701857051\n",
      "dirpath: 5536760882825901738\n",
      "dirpath: 5536745420943636139\n",
      "dirpath: 5537143564411975377\n",
      "dirpath: 5539444807889172133\n",
      "dirpath: 5536038039829982468\n",
      "dirpath: 5536876846942893978\n",
      "dataset_i: 5539702505926936192\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5539826200985059108\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5537693749722594824\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5538635636050605931\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5539444807889172133\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5539474443163516678\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5537751731781090844\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5535423430009926848\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5539741160632598296\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5537369050195015499\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5537514649586349811\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5536745420943636139\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5535496873950688380\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5537143564411975377\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5535415699068794046\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5536876846942893978\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5536760882825901738\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5536266102593401990\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5539535002202392187\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5536968329746298779\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5537893465701857051\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5537522380527482610\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5536915501648559593\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5535864093654496929\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5537885734760724252\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "dataset_i: 5536038039829982468\n",
      "video_result: ['00065', '00012', '00018', '00014', '00001', '00040', '00015', '00032', '00011', '00041', '00030', '00010', '00058', '00024', '00034', '00059', '00044', '00036', '00006', '00019', '00007', '00072', '00035', '00013', '00026', '00048', '00060', '00073', '00056', '00068', '00070', '00009', '00002']\n",
      "5535864093654496929\n",
      "5538635636050605931\n",
      "5537751731781090844\n",
      "5537369050195015499\n",
      "5537514649586349811\n",
      "5539474443163516678\n",
      "5537522380527482610\n",
      "5536266102593401990\n",
      "5536915501648559593\n",
      "5539826200985059108\n",
      "5539535002202392187\n",
      "5539702505926936192\n",
      "5535423430009926848\n",
      "5537693749722594824\n",
      "5536968329746298779\n",
      "5539741160632598296\n",
      "5537885734760724252\n",
      "5535496873950688380\n",
      "5535415699068794046\n",
      "5537893465701857051\n",
      "5536760882825901738\n",
      "5536745420943636139\n",
      "5537143564411975377\n",
      "5539444807889172133\n",
      "5536038039829982468\n",
      "5536876846942893978\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from glob import glob\n",
    "import shutil,os\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "\n",
    "# 去除名字的特殊符号，统一序号视频文件命名\n",
    " \n",
    "# def original_video_name_format():\n",
    "#     base_path = \"../LSR2/main\"\n",
    "#     result = list(glob(\"{}/*\".format(base_path),recursive=False))\n",
    "#     file_num = 0\n",
    "#     result_list = []\n",
    " \n",
    "#     for each in result:\n",
    "#         file_num +=1\n",
    "#         new_position =\"{0}{1}\".format( int(time.time()),file_num)\n",
    "#         result_list.append(new_position)\n",
    "#         shutil.move(each, os.path.join(base_path,new_position+\".mp4\"))\n",
    "#         pass\n",
    "\n",
    "def trained_data_name_format():\n",
    "    base_path = \"../LSR2/lrs2_preprocessed\"\n",
    "    # result = list(glob(\"{}/*\".format(base_path)))\n",
    "    result = os.listdir(base_path)\n",
    "    print(result)\n",
    "    result_list = []\n",
    "    for i,dirpath in enumerate(result):\n",
    "        # shutil.move(dirpath,\"{0}/{1}\".format(base_path,i))\n",
    "        # result_list.append(str(i))\n",
    "        # print('dirpath:', dirpath)\n",
    "        result_list.append(dirpath)\n",
    "    if len(result_list)<14:\n",
    "        test_result=val_result=train_result=result_list\n",
    "    else:\n",
    "        train_result,test_result = train_test_split(result_list,test_size=0.15, random_state=42)\n",
    "        test_result, val_result = train_test_split(test_result, test_size=0.5, random_state=42)\n",
    " \n",
    "    for file_name,dataset in zip((\"train.txt\",\"test.txt\",\"val.txt\"),(train_result,test_result,val_result)):\n",
    "        with open(os.path.join(\"filelists\",file_name),'w',encoding='utf-8') as fi:\n",
    "            for dataset_i in dataset:\n",
    "                # print('dataset_i:', dataset_i)\n",
    "                video_result = os.listdir(os.path.join(base_path, dirpath))\n",
    "                # print('video_result:', video_result)\n",
    "                video_result = [dataset_i+'/'+video for video in video_result]\n",
    "                fi.write(\"\\n\".join(video_result))\n",
    "                fi.write(\"\\n\")\n",
    " \n",
    "    # print(\"\\n\".join(result_list))\n",
    "\n",
    "trained_data_name_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6d2a7-7f3e-40ea-96c4-996aaee42a32",
   "metadata": {},
   "source": [
    "Training the expert discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf0bb64-29af-486d-b14e-5eecf0be8c17",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n",
      "total trainable params 16435072\n",
      "Load checkpoint from: ./checkpoints/lipsync_expert.pth\n",
      "Load optimizer state from ./checkpoints/lipsync_expert.pth\n",
      "Loss: 0.40534352511167526: : 12it [00:05,  2.18it/s]\n",
      "Loss: 0.3580533017714818: : 12it [00:02,  4.13it/s] \n",
      "Loss: 0.32754940415422124: : 12it [00:02,  4.90it/s]\n",
      "Loss: 0.29246504480640095: : 12it [00:02,  5.00it/s]\n",
      "Loss: 0.2891663412253062: : 12it [00:02,  4.50it/s]\n",
      "Loss: 0.30349138379096985: : 12it [00:03,  3.86it/s]\n",
      "Loss: 0.2882717673977216: : 12it [00:02,  5.12it/s]\n",
      "Loss: 0.273677296936512: : 12it [00:02,  4.07it/s]  \n",
      "Loss: 0.2897895773251851: : 12it [00:02,  5.14it/s]\n",
      "Loss: 0.2912977859377861: : 12it [00:02,  4.91it/s] \n",
      "Loss: 0.25479352350036305: : 12it [00:02,  4.56it/s]\n",
      "Loss: 0.27851927901307744: : 12it [00:02,  5.00it/s]\n",
      "Loss: 0.2553818387289842: : 12it [00:02,  4.84it/s] \n",
      "Loss: 0.270049549639225: : 12it [00:02,  4.40it/s]  \n",
      "Loss: 0.2607487055162589: : 12it [00:02,  5.01it/s] \n",
      "Loss: 0.25605521475275356: : 12it [00:02,  4.54it/s]\n",
      "Loss: 0.256984422604243: : 12it [00:02,  4.84it/s]  \n",
      "Loss: 0.23982644081115723: : 12it [00:02,  4.90it/s]\n",
      "Loss: 0.2589375066260497: : 12it [00:02,  4.28it/s]\n",
      "Loss: 0.23917076860864958: : 12it [00:02,  4.62it/s]\n",
      "Loss: 0.23177950456738472: : 12it [00:02,  5.20it/s]\n",
      "Loss: 0.25006572157144547: : 12it [00:02,  4.06it/s]\n",
      "Loss: 0.2542072782913844: : 12it [00:02,  4.55it/s] \n",
      "Loss: 0.2563767023384571: : 12it [00:02,  4.71it/s]\n",
      "Loss: 0.25271571675936383: : 12it [00:03,  3.78it/s]\n",
      "Loss: 0.2342692737778028: : 12it [00:02,  4.74it/s] \n",
      "Loss: 0.2665197526415189: : 12it [00:02,  5.49it/s] \n",
      "Loss: 0.2378075954814752: : 12it [00:03,  3.58it/s] \n",
      "Loss: 0.24679724996288618: : 12it [00:02,  4.90it/s]\n",
      "Loss: 0.23419532179832458: : 12it [00:02,  4.93it/s]\n",
      "Loss: 0.21885045866171518: : 12it [00:02,  4.54it/s]\n",
      "Loss: 0.23329471300045648: : 12it [00:02,  4.54it/s]\n",
      "Loss: 0.22117950394749641: : 12it [00:02,  5.24it/s]\n",
      "Loss: 0.23309461027383804: : 12it [00:02,  4.31it/s]\n",
      "0it [00:00, ?it/s]^C\n",
      "0it [00:01, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/yeahmobi/Wav2Lip/color_syncnet_train.py\", line 276, in <module>\n",
      "    train(device, model, train_data_loader, test_data_loader, optimizer,\n",
      "  File \"/home/ec2-user/SageMaker/yeahmobi/Wav2Lip/color_syncnet_train.py\", line 149, in train\n",
      "    for step, (x, mel, y) in prog_bar:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/tqdm/std.py\", line 1178, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1295, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/connection.py\", line 424, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python color_syncnet_train.py --data_root ../LSR2/lrs2_preprocessed/ --checkpoint_dir ./savedmodel --checkpoint_path ./checkpoints/lipsync_expert.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b3dc53-722f-428e-8305-7b9d42ae082a",
   "metadata": {},
   "source": [
    "执行如下命令，开始训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b989d6e-be14-47fc-9f10-2226f02bc4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n",
      "total trainable params 36298035\n",
      "Load checkpoint from: ./checkpoints/wav2lip.pth\n",
      "Load optimizer state from ./checkpoints/wav2lip.pth\n",
      "Load checkpoint from: ./checkpoints/lipsync_expert.pth\n",
      "Starting Epoch: 203\n",
      "0it [00:00, ?it/s]^C\n"
     ]
    }
   ],
   "source": [
    "!python wav2lip_train.py --data_root ../LSR2/lrs2_preprocessed --checkpoint_dir ./savedmodel --syncnet_checkpoint_path ./checkpoints/lipsync_expert.pth --checkpoint_path ./checkpoints/wav2lip.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4764fda7-3c76-45d8-be8f-391ad409a361",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n",
      "total trainable params 36298035\n",
      "total DISC trainable params 14113793\n",
      "Load checkpoint from: ./checkpoints/wav2lip.pth\n",
      "Load optimizer state from ./checkpoints/wav2lip.pth\n",
      "Load checkpoint from: ./checkpoints/visual_quality_disc.pth\n",
      "Load optimizer state from ./checkpoints/visual_quality_disc.pth\n",
      "Load checkpoint from: ./checkpoints/lipsync_expert.pth\n",
      "Starting Epoch: 203\n",
      "L1: 0.032601705711820854, Sync: 0.0, Percep: 1.0678514177384584 | Fake: 0.5464184919129247, Real: 0.5613359776527985: : 46it [00:18,  2.44it/s]\n",
      "Starting Epoch: 204\n",
      "L1: 0.04400158479161884, Sync: 0.0, Percep: 1.028250489545905 | Fake: 0.5532738423865774, Real: 0.5383027455081111: : 46it [00:15,  2.97it/s]  \n",
      "Starting Epoch: 205\n",
      "L1: 0.041590580344200136, Sync: 0.0, Percep: 1.0814215958118438 | Fake: 0.5159455627202988, Real: 0.47654434740543367: : 10it [00:04,  3.09it/s]^C\n",
      "L1: 0.041590580344200136, Sync: 0.0, Percep: 1.0814215958118438 | Fake: 0.5159455627202988, Real: 0.47654434740543367: : 10it [00:04,  2.31it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/yeahmobi/Wav2Lip/hq_wav2lip_train.py\", line 440, in <module>\n",
      "    train(device, model, disc, train_data_loader, test_data_loader, optimizer, disc_optimizer,\n",
      "  File \"/home/ec2-user/SageMaker/yeahmobi/Wav2Lip/hq_wav2lip_train.py\", line 213, in train\n",
      "    disc.train()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 2269, in train\n",
      "    def train(self: T, mode: bool = True) -> T:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python hq_wav2lip_train.py --data_root ../LSR2/lrs2_preprocessed --checkpoint_dir ./savedmodel --syncnet_checkpoint_path ./checkpoints/lipsync_expert.pth --checkpoint_path ./checkpoints/wav2lip.pth --disc_checkpoint_path ./checkpoints/visual_quality_disc.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65d7f59-801e-4e1a-acbf-b8353fb6d387",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference.\n",
      "Reading video frames...\n",
      "Number of frames available for inference: 57\n",
      "(80, 185)\n",
      "Length of mel chunks: 55\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 1/4 [00:02<00:07,  2.35s/it]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.11s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:02<00:00,  1.41it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:03<00:00,  1.16it/s]\u001b[A\n",
      "Load checkpoint from: ./checkpoints/wav2lip_gan.pth\n",
      "Model loaded\n",
      "100%|█████████████████████████████████████████████| 1/1 [01:37<00:00, 97.80s/it]\n",
      "ffmpeg version 4.2.3 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7.5.0 (crosstool-NG 1.24.0.123_1667d2b)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1590573566052/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1590573566052/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-libx264 --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
      "\u001b[0mInput #0, wav, from '../LSR2/lrs2_preprocessed_288x288-demo/5539702505926936192/00001/audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:02.30, bitrate: 256 kb/s\n",
      "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Input #1, avi, from 'temp/result.avi':\n",
      "  Metadata:\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:02.20, start: 0.000000, bitrate: 350 kb/s\n",
      "    Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 160x160 [SAR 1:1 DAR 1:1], 330 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mprofile High, level 1.1\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0m264 - core 152 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=5 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'results/result_voice.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 160x160 [SAR 1:1 DAR 1:1], q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 16000 Hz, mono, fltp, 69 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "frame=   55 fps=0.0 q=-1.0 Lsize=      59kB time=00:00:02.30 bitrate= 208.7kbits/s speed=26.7x    \n",
      "video:37kB audio:20kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 4.340654%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mframe I:1     Avg QP:25.51  size:  3119\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mframe P:46    Avg QP:26.10  size:   683\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mframe B:8     Avg QP:29.88  size:   285\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mconsecutive B-frames: 78.2%  3.6% 10.9%  7.3%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mmb I  I16..4:  1.0% 90.0%  9.0%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mmb P  I16..4:  0.0%  0.6%  0.0%  P16..4: 45.0% 32.8% 14.8%  0.0%  0.0%    skip: 6.7%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mmb B  I16..4:  0.0%  0.1%  0.2%  B16..8: 53.9% 11.6%  2.4%  direct: 3.8%  skip:28.0%  L0:38.6% L1:42.5% BI:18.9%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0m8x8 transform intra:88.8% inter:70.1%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mcoded y,uvDC,uvAC intra: 96.5% 100.0% 76.1% inter: 38.8% 36.4% 0.9%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mi16 v,h,dc,p:  0%  0%  0% 100%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 15% 15%  5%  5% 10%  4%  9%  8%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 11% 10%  8% 11% 18% 10%  8% 10%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mi8c dc,h,v,p: 43% 10% 28% 19%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mref P L0: 73.1% 20.9%  4.8%  1.2%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mref B L0: 96.4%  3.6%\n",
      "\u001b[1;36m[libx264 @ 0x5645e3e70140] \u001b[0mkb/s:133.92\n",
      "\u001b[1;36m[aac @ 0x5645e3e505c0] \u001b[0mQavg: 136.509\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference.py --checkpoint_path ./checkpoints/wav2lip_gan.pth --face ../LSR2/demo/5539702505926936192/00001.mp4 --audio ../LSR2/lrs2_preprocessed_288x288-demo/5539702505926936192/00001/audio.wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386239f-9172-4fbb-b31d-7c0f7dcb94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../LSR2/lrs2_preprocessed_288x288-demo/5539702505926936192/00001/final_results/ && ffmpeg -r 25 -i %d.png 00001-sr.mp4 -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ae7dc9-fab4-46d8-aa54-251eef8b92e6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference.\n",
      "Reading video frames...\n",
      "Number of frames available for inference: 57\n",
      "(80, 185)\n",
      "Length of mel chunks: 55\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████                                 | 1/4 [01:45<05:15, 105.07s/it]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [01:47<01:29, 44.69s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:49<00:25, 25.24s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:57<00:00, 29.44s/it]\u001b[A\n",
      "Load checkpoint from: ./checkpoints/wav2lip_gan.pth\n",
      "Model loaded\n",
      "100%|████████████████████████████████████████████| 1/1 [02:02<00:00, 122.76s/it]\n",
      "ffmpeg version 4.2.3 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7.5.0 (crosstool-NG 1.24.0.123_1667d2b)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1590573566052/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1590573566052/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-libx264 --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
      "\u001b[0mInput #0, wav, from '../LSR2/lrs2_preprocessed_288x288-demo/5539702505926936192/00001/audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:02.30, bitrate: 256 kb/s\n",
      "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Input #1, avi, from 'temp/result.avi':\n",
      "  Metadata:\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:02.20, start: 0.000000, bitrate: 6577 kb/s\n",
      "    Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 1024x1208 [SAR 1:1 DAR 128:151], 6671 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mprofile High, level 3.2\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0m264 - core 152 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'results/result_voice.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 1024x1208 [SAR 1:1 DAR 128:151], q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 16000 Hz, mono, fltp, 69 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 aac\n",
      "frame=   55 fps= 27 q=-1.0 Lsize=    1064kB time=00:00:02.30 bitrate=3782.7kbits/s speed=1.15x    \n",
      "video:1042kB audio:20kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.252787%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mframe I:3     Avg QP:21.46  size: 23256\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mframe P:23    Avg QP:23.76  size: 20015\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mframe B:29    Avg QP:24.16  size: 18476\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mconsecutive B-frames: 27.3%  3.6% 10.9% 58.2%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mmb I  I16..4: 26.6% 73.3%  0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mmb P  I16..4: 17.8% 42.3%  0.1%  P16..4: 32.6%  4.6%  0.7%  0.0%  0.0%    skip: 1.9%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mmb B  I16..4:  7.8% 22.3%  0.0%  B16..8: 45.4%  8.1%  0.5%  direct: 4.5%  skip:11.3%  L0:67.0% L1:30.8% BI: 2.2%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0m8x8 transform intra:71.9% inter:95.4%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mcoded y,uvDC,uvAC intra: 42.1% 69.5% 1.0% inter: 24.1% 55.4% 0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mi16 v,h,dc,p: 25% 17% 13% 45%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 33% 21% 31%  3%  3%  3%  2%  3%  2%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 35% 19% 12%  3% 11%  8%  6%  4%  2%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mi8c dc,h,v,p: 45% 20% 28%  7%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mref P L0: 71.8%  4.9% 15.1%  8.2%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mref B L0: 83.6% 11.8%  4.6%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mref B L1: 92.0%  8.0%\n",
      "\u001b[1;36m[libx264 @ 0x5595f15c7600] \u001b[0mkb/s:3876.06\n",
      "\u001b[1;36m[aac @ 0x5595f15c6280] \u001b[0mQavg: 136.509\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference.py --checkpoint_path ./checkpoints/wav2lip_gan.pth --face ../LSR2/lrs2_preprocessed_288x288-demo/5539702505926936192/00001/final_results/00001-sr.mp4 --audio ../LSR2/lrs2_preprocessed_288x288-demo/5539702505926936192/00001/audio.wav\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30478.041156,
   "end_time": "2021-08-02T23:30:53.753624",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-02T15:02:55.712468",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
